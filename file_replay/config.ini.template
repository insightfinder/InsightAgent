[agent]
## files
# comma-delimited list of absolute file paths. If any are a directory, all files in that directory will be loaded.
file_path = 
# regex for file names (does not include the file path)
file_name_regex = 

## filters
# define a list of filters to use as field:allowed values|field:allowed values
# for example:
#   message.env:stg,prd|message.status:complete
filters_include = 
# as above, but instead define values that are not allowed
# for example:
#   message.env:dev,cde|message.status:draft
filters_exclude = 

# raw, rawtail, csv, csvtail, xls, xlsx, json, jsontail, avro, or xml
# *tail formats keep track of the current file & position + completed files in [state] below
data_format = 

## RAW
# if raw data, the regex used to parse the log. It must use named capture groups `(?<name>.*)` that correspond to the *_field config variables below (ie  `(?<timestamp>.*)`,  `(?<host>.*)`,  `(?<device>.*)`,  `(?<etc>.*)`. The raw message will be treated as a field named `_raw`
raw_regex = 
# if the log is multiline, the regex that indicates that the line is the start of a new message. this MUST start with ^ (unless blank)
raw_start_regex = 

## CSV, XLS, XLSX
# Required - field names, in order as timestamp,field1,field2...
csv_field_names =
# a regex string used to delimit "csv" fields (ie the default ,|\t matches a comma or tab character)
csv_field_delimiter = ,|\t

## JSON, AVRO, XML
# for multi-entry messages, define the top-level
#   if messages are [{message1}, {message2}], set top_level = []
#   it's expected that the top level will be a list
# fields in json can be defined as level0.level1.levelN
json_top_level = 

## message parsing
# timestamp format, as per python strptime. multiple fields can be formatted together to create the timestamp a la `{date} {time}`, where `date` and `time` are fields that each contain part of the timestamp. If multiple fields could contain the timestamp, a comma-delimited list may be entered (no value of which may use the aforementioned {formatting}), of which the first found will be selected (treating the list as a priority list). ex `timestamp1,timestamp2`.
timestamp_format = epoch
# timezone, as per pytz
timezone = 
timestamp_field = timestamp
# if no instance given, the local hostname will be used. Can also use {field} formatting or a priority list.
instance_field = host
device_field = 
# multiple fields are separated by commas. a field can be named with the syntax `<name>:<value>` or `<name>:=<value>`, where `<name>` and `<value>` can each be either a literal value (`name:value`) or formatted (`Total Time [{step}]:={timing.end}-{timing.start}`). Use `:=` as a separator to treat `<value>` as a mathematical formula, which must be parseable by `eval()`.
data_fields =

[insightfinder]
user_name = 
license_key = 
token =
project_name = 
# metric, metricreplay, log, logreplay, incident, incidentreplay, alert, alertreplay, deployment, deploymentreplay
project_type = 
sampling_interval = 1
run_interval = 10
# what size to limit chunks sent to IF to, as kb
chunk_size_kb = 2048
if_url = https://app.insightfinder.com
if_http_proxy =
if_https_proxy =

[state]
## do not edit the below fields
current_file =
current_file_offset =
completed_files_st_ino = 
